{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load benchmark files to memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# filename = \"./xsbench-setup/benchmark_results.txt\"\n",
                "# filename = \"./rsbench-setup/benchmark_results.txt\"\n",
                "# filename = \"./minifmm-setup/benchmark_results.txt\"\n",
                "filename = \"./simple-offload/benchmark_results.txt\"\n",
                "\n",
                "# set metadata based on filename\n",
                "if \"minifmm\" in filename:\n",
                "    exp_kind = \"MiniFMM\"\n",
                "    instrumented_label = \"Simulation time\"\n",
                "    hide_x_ticks = True\n",
                "    x_axis_label = \"plummer\"\n",
                "\n",
                "if \"rsbench\" in filename:\n",
                "    exp_kind = \"RSBench\"\n",
                "    instrumented_label = \"Simulation time\"\n",
                "    hide_x_ticks = True\n",
                "    x_axis_label = \"Doppler broadening\"\n",
                "\n",
                "if \"xsbench\" in filename:\n",
                "    exp_kind = \"XSBench\"\n",
                "    instrumented_label = \"Simulation time\"\n",
                "    hide_x_ticks = True\n",
                "    x_axis_label = \"unionize\"\n",
                "\n",
                "if \"simple-offload\" in filename:\n",
                "    exp_kind = \"Host to Device offload\"\n",
                "    instrumented_label = \"target data map\"\n",
                "    x_axis_label = \"Payload size (MB)\"\n",
                "    hide_x_ticks = False\n",
                "\n",
                "\n",
                "benchmarks = []\n",
                "\n",
                "data = open(f\"{filename}\", \"r\").read()\n",
                "output_dir = f\"./pdf/{filename}\"\n",
                "if not os.path.exists(output_dir):\n",
                "    os.makedirs(output_dir)\n",
                "\n",
                "for line in data.split('\\n'):\n",
                "    info = line.split(',')\n",
                "    if len(info) > 2:\n",
                "        wall_time = float(info[0])\n",
                "        data_time = float(info[1])\n",
                "        size = 0\n",
                "        if info[2] != \"none\":\n",
                "            size = float(info[2])\n",
                "        use_as = True if int(info[3]) == 1 else False\n",
                "        if use_as:\n",
                "            heuristic = info[4]\n",
                "        topo = info[5]\n",
                "\n",
                "        if use_as:\n",
                "            exp_name = f\"{heuristic}\"\n",
                "        else:\n",
                "            exp_name = \"Baseline\"\n",
                "\n",
                "        benchmark_info = {\n",
                "            \"experiment_kind\": exp_name,\n",
                "            \"x_axis_metric\": float(size),\n",
                "            \"wall_execution_time\": wall_time,\n",
                "            \"instrumented_time\": data_time,\n",
                "            \"application_name\": exp_kind,\n",
                "        }\n",
                "        benchmarks.append(benchmark_info)\n",
                "\n",
                "df = pd.DataFrame(benchmarks)\n",
                "\n",
                "# get number of executions per x_axis_metric\n",
                "n_executions = df.groupby([\"experiment_kind\", \"x_axis_metric\"]).size().reset_index(name='n_executions')\n",
                "# check if all experiments have the same number of executions\n",
                "assert len(n_executions[\"n_executions\"].unique()) == 1\n",
                "n_executions = n_executions[\"n_executions\"].unique()[0]\n",
                "print(df.head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cosmetic options"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "\n",
                "colors = [\n",
                "    \"#7f7f7f\", # grey\n",
                "    \"#621dac\", # main purple\n",
                "    \"#c5702d\", # orange\n",
                "    \"#000000\", # black,\n",
                "    \"#099892\", # teal\n",
                "    \"#ffd400\", # yellow\n",
                "    \"#7e57c4\", # pink/purple,\n",
                "]\n",
                "\n",
                "# Calculate the remainder time (wall time - instrumented time)\n",
                "df[\"remainder_time\"] = df[\"wall_execution_time\"] - df[\"instrumented_time\"]\n",
                "print(df.head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plot total execution times with bootstrap errorbars"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "# Set the style for the plot (optional)\n",
                "sns.set(style=\"whitegrid\")\n",
                "\n",
                "for measurment in ['wall_execution_time', 'instrumented_time']:\n",
                "    measurment_name = 'Total time' if measurment == 'wall_execution_time' else instrumented_label\n",
                "\n",
                "    for experiment in df[\"application_name\"].unique():\n",
                "        application_df = df[df[\"application_name\"] == experiment]\n",
                "\n",
                "        # Create the bar plot with bootstrap confidence intervals\n",
                "        ax = plt.figure(figsize=(5, 5))  # Adjust the figure size as needed\n",
                "\n",
                "        x_clips = [\n",
                "            (-math.inf, math.inf),\n",
                "            # (0, 201),\n",
                "            # (201, 16000)\n",
                "        ]\n",
                "\n",
                "        # in percentages\n",
                "        y_clips = [\n",
                "            0,\n",
                "           10\n",
                "        ]\n",
                "\n",
                "        for y_clip in y_clips:\n",
                "            for x_clip in x_clips:\n",
                "                _application = application_df[application_df[\"x_axis_metric\"] >= x_clip[0]]\n",
                "                _application = _application[application_df[\"x_axis_metric\"] < x_clip[1]]\n",
                "                if _application.empty:\n",
                "                    continue\n",
                "\n",
                "                sns.barplot(\n",
                "                    data=_application,\n",
                "                    x=\"x_axis_metric\",\n",
                "                    y=measurment,\n",
                "                    hue=\"experiment_kind\",\n",
                "                    errorbar='ci', n_boot=1000,\n",
                "                    alpha=.95,\n",
                "                )\n",
                "\n",
                "                if y_clip > 0:\n",
                "                    # minimum value\n",
                "                    min_value = _application[measurment].min() \n",
                "                    min_value = min_value - (min_value * y_clip / 100)\n",
                "                    min_value = math.floor(min_value)\n",
                "                    min_value = min_value if min_value > 0 else 0\n",
                "                    plt.ylim(bottom=min_value)\n",
                "\n",
                "                plt.xlabel(\"Message size (MB)\")\n",
                "                plt.ylabel(f\"{measurment_name} (s)\")\n",
                "                plt.xticks(rotation=45)\n",
                "                if hide_x_ticks:\n",
                "                    plt.xticks([])\n",
                "                plt.xlabel(x_axis_label)\n",
                "                plt.title(f\"{experiment} - {measurment_name}\\n {n_executions} executions - Error bar = 95% CI (1000 bootstraps)\\n\")\n",
                "                plt.legend(title=\"Strategy\")\n",
                "\n",
                "                pdf_name = f\"{experiment.replace(' ', '_')}_{measurment}_yclip_{y_clip}_{x_clip[0]}_{x_clip[1]}.pdf\"\n",
                "                plt.savefig(f\"{output_dir}/{pdf_name}\", bbox_inches='tight')\n",
                "                plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Stacked segmented time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for application in df[\"application_name\"].unique():\n",
                "    application_df = df[df[\"application_name\"] == application]\n",
                "\n",
                "    # Get the unique kinds of experiments\n",
                "    for experiment in application_df[\"experiment_kind\"].unique():\n",
                "        # Filter the DataFrame to include only \n",
                "        experiment_df = application_df[application_df[\"experiment_kind\"] == experiment]\n",
                "\n",
                "        # Group the data by 'x_axis_metric' and calculate the mean for each group\n",
                "        mean_df = experiment_df.groupby(\"x_axis_metric\").mean(numeric_only=True).reset_index()\n",
                "\n",
                "        # Create the stacked bar plot\n",
                "        plt.figure(figsize=(5, 5))  # Adjust the figure size as needed\n",
                "\n",
                "        # Set the x-axis positions for each bar\n",
                "        x_names = mean_df[\"x_axis_metric\"]\n",
                "        x_names = [str(x) for x in x_names]\n",
                "        x = np.arange(len(x_names))\n",
                "\n",
                "        # Plot the instrumented time as a stacked bar\n",
                "        plt.bar(\n",
                "            x,\n",
                "            mean_df[\"instrumented_time\"],\n",
                "            label=instrumented_label,\n",
                "            color=colors[2],\n",
                "            alpha=0.9,\n",
                "        )\n",
                "\n",
                "        # Plot the remainder time as a stacked bar on top of the instrumented time\n",
                "        plt.bar(\n",
                "            x,\n",
                "            mean_df[\"remainder_time\"],\n",
                "            bottom=mean_df[\"instrumented_time\"],\n",
                "            label='Remainder',\n",
                "            color=colors[4],\n",
                "            alpha=0.9,\n",
                "        )\n",
                "        plt.xlabel(x_axis_label)\n",
                "        plt.xticks(x, x_names, rotation=45)\n",
                "        plt.ylabel(\"Time (s)\")\n",
                "        plt.title(f\"{application} - {experiment} experiment\")\n",
                "        plt.legend(title=\"Time component\")\n",
                "        if hide_x_ticks:\n",
                "            plt.xticks([])\n",
                "\n",
                "        pdf_name = f\"stacked_{experiment.replace(' ', '_')}.pdf\"\n",
                "        plt.savefig(f\"{output_dir}/{pdf_name}\", bbox_inches='tight')\n",
                "        plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
